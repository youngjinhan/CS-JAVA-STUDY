# Part 1 운영체제
---
# 프로세스(Process)
---
## 프로세스가 무엇인가요?
1. 프로세스가 무엇인가요?
    - Process와 Program 차이점 설명
        - Program: 어떤 작업을 위해 실행할 수 있는 파일을 의미한다
        - Process:  실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU의 할당을 받은 작업의 단위다.
    - Process와 Thread 차이점 설명
        - Light-weight process = Thread
        - 멀티 프로세스, 멀티 스레드 정의와 속도차이
            
            **Multi Process 와 Multi Thread**
            
            특정 프로세스가 자식프로세스를 생성하는 경우 ( Multi Process )
            
            1. 부모 프로세스의 메모리 영역을 모두 복제하기 때문에, 시간 및 공간이 많이 소요됩니다.
            
            2. 또한 독립적인 메모리 영역을 가지기 때문에 데이터를 공유하기 어렵습니다.
            
            3. 대신 어느 프로세스에서 장애가 발생한다고 하여, 다른 프로세스에 영향을 미치지 않습니다.
            
            특정 프로세스가 스레드를 생성하는 경우 ( Multi Thread )
            
            1. 하나의 프로세스의 메모리를 공유하기 때문에 메모리 사용량이 감소합니다.
            
            2. 메모리 영역을 공유하므로 데이터 공유를 쉽게 할 수 있습니다.
            
            3. Multi Process 대비 수행속도가 증가하게 됩니다.
            
            4. 특정 Thread 에서 장애가 발생할 경우, 프로세스에 영향을 미치므로 다른 Thread 까지 영향을 받을 수 있습니다.
            
        - 크롬의 탭은 프로세스인가 스레드인가
            - 정답은 **Process**다.
                
                ![https://blog.kakaocdn.net/dn/IFwqc/btqMBv1vYDB/Yb7nM87hNsdYJMOSkSMPwK/img.png](https://blog.kakaocdn.net/dn/IFwqc/btqMBv1vYDB/Yb7nM87hNsdYJMOSkSMPwK/img.png)
                
                실험을 위해 Chrome에서 Tab 세 개를 만들었다.
                
                wmic process get Caption, ParentProcessId, ProcessId | find /i "chrome"
                
                CMD에 명령했다.
                
                ![https://blog.kakaocdn.net/dn/bc6Ld1/btqMBvHbfWl/3J7XFOOEkuSxR4DywYHe70/img.png](https://blog.kakaocdn.net/dn/bc6Ld1/btqMBvHbfWl/3J7XFOOEkuSxR4DywYHe70/img.png)
                
                굉장히 많은 chrome Process가 생겼다.
                
                주목해야할 점은 이들의 PPID 와 PID이다. PPID는 부모의 PID를 의미한다.
                
                그림에서 왼쪽에 있는게 각 프로세스의 PPID이고 오른쪽이 PID이다.
                
                제일 위에 있는 프로세스의 PID가 20668이고, 그 밑의 모든 프로세스의 PPID가 20668이므로
                
                제일 위에 있는 **프로세스가 모든 프로세스의 부모 프로세스**이다.
                
                ![https://blog.kakaocdn.net/dn/bgUKys/btqMGOM3pRm/bj4wVdYgg8uLKrMRloa0R1/img.png](https://blog.kakaocdn.net/dn/bgUKys/btqMGOM3pRm/bj4wVdYgg8uLKrMRloa0R1/img.png)
                
                https://www.chromium.org/developers/design-documents/plugin-architecture
                
                위에 있는 게 Chromium의 구조이다.
                
                그림에서 알 수 있다시피 각 프로세스는 **IPC(Inter Process Communication)**로 소통한다.
                
                ![https://blog.kakaocdn.net/dn/bc6Ld1/btqMBvHbfWl/3J7XFOOEkuSxR4DywYHe70/img.png](https://blog.kakaocdn.net/dn/bc6Ld1/btqMBvHbfWl/3J7XFOOEkuSxR4DywYHe70/img.png)
                
                최상위 chrome.exe가 아닌, 다른 chrome.exe는 Kill해도 창 자체가 꺼지지는 않지만
                
                최상위 chrome.exe를 종료할 경우 브라우저 자체가 종료된다.
                
                **왜 Process로 했지?**
                
                Multi-thread Architecture는 성능면에서 유리하지만, 안정성과 보안 등에서 취약하다.
                
                그래서 chromium은 Multi-process Architecture를 선택했다.
                
    - 프로세스와 스레드는 각각 어떻게 생성
        - 프로세스는 각각 별도의 메모리 영역(주소 공간)을 할당받는다. [Code, Data, Stack, Heap]
        - 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없으며, 접근을 위해서는 IPC 통신이 필요하다.
            - Ex) 파이프, 파일, 소켓 등을 이용한 통신 방법 이용.
        - 스레드는 프로세스 내의 Code, Data, Heap 영역은 다른 스레드와 공유하고 Stack 영역을 따로 할당받는다.
        - 여러 스레드는 한 프로세스 내의 Code, Data, Heap 영역을 공유하지만, 프로세스 간에는 메모리에 접근할 수 없다.
        - 스레드는 별도의 레지스터와 스택을 갖고 있으며, 다른 영역을 공유한다. 따라서 한 스레드가 프로세스의 자원을 변경하면, 다른 스레드도 그 변경 결과를 즉시 확인할 수 있다.
        - 프로세스와 스레드는 각각 다른 방식으로 생성됩니다
            
            
            프로세스는 운영 체제에 의해 생성되며, 보통은 다음과 같은 단계를 거칩니다.
            
            1. 프로세스 생성을 요청하는 프로그램이나 사용자에 의해 운영 체제에 요청됩니다.
            2. 운영 체제는 새로운 프로세스를 위한 공간을 할당합니다. 이 공간에는 코드, 데이터, 스택 등이 포함됩니다.
            3. 운영 체제는 새로운 프로세스를 실행하기 위해 초기화 작업을 수행합니다. 이 작업에는 프로세스의 초기 상태를 설정하는 것이 포함됩니다.
            4. 운영 체제는 새로운 프로세스를 실행합니다.
            
            스레드는 프로세스 내에서 생성됩니다. 스레드를 생성하는 방법은 운영 체제나 프로그래밍 언어에 따라 다르지만, 대부분의 경우 다음과 같은 단계를 거칩니다.
            
            1. 프로세스 내에서 스레드 생성 함수를 호출합니다. 이 함수는 새로운 스레드를 만들고, 스레드 ID를 반환합니다.
            2. 새로운 스레드는 프로세스 내에서 실행될 함수를 지정합니다.
            3. 스레드는 생성되고, 스레드 함수를 실행합니다.
            
            이처럼 프로세스와 스레드는 서로 다른 방식으로 생성됩니다. 프로세스는 운영 체제에 의해 생성되고 실행되며, 스레드는 프로세스 내에서 생성되고 실행됩니다.
            
        
    - 프로세스 메모리 구조 설명
        1. 초기화 하지 않은 변수들
            1. 초기화되지 않은 전역 변수가 위치하는 공간을 BSS(block started by symbol) 영역이라고 부른다.
        2. 동적 라이브러리 접근
            - **동적 연결 및 공유 라이브러리**
                - 동적 연결 라이브러리(DDL) : 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리, 함수, 루틴이 호출될때 동적 라이브러리 주소에서 참조하게된다.
                - 정적 연결 라이브러리 : 프로그램을 생성할때, 정적 라이브러리는 이진 프로그램 이미지에 붙여넣어진다.
                - 동적 라이브러리의 장점
                    1. 프로그램의 실행파일의 크기를 줄일 수 있다.
                    2. 여러 프로세스가 라이브러리를 공유할 수 있다.
                        - 이러한 이유로 `공유 라이브러리`라고도 불린다.
            
        3. Stack Size는 언제 결정되냐?
            - 프로세스가 생성될 때 운영체제에서 미리 정의된 기본값으로 생성
                
                Stack Size(스택 크기)는 프로세스의 메모리 구성 요소 중 하나로, 프로세스가 사용하는 스택 영역의 크기를 결정합니다. 스택은 함수 호출과 관련된 데이터를 저장하는 데 사용되는 메모리 영역이며, 일반적으로 프로그래밍 언어에서 지역 변수, 함수 인자, 리턴 값 등이 저장됩니다.
                
                스택 크기는 프로세스가 생성될 때 결정됩니다. 일반적으로 스택 크기는 운영 체제에서 미리 정의된 기본값을 사용하며, 이 값은 운영 체제나 컴파일러에서 설정할 수 있습니다. 또한 프로그램에서 명시적으로 스택 크기를 지정할 수도 있습니다.
                
                스택 크기는 크게 두 가지 요인에 따라 결정됩니다. 첫째, 프로그램에서 사용하는 데이터의 크기와 깊이(즉, 재귀 함수 호출 수준)에 따라 스택 크기가 결정됩니다. 둘째, 운영 체제의 스택 크기 제한에 따라 결정됩니다. 대부분의 운영 체제에서는 각 프로세스마다 스택 크기의 제한을 둡니다. 이 제한은 운영 체제에서 설정되며, 일반적으로 수백 킬로바이트에서 몇 메가바이트 정도의 범위 내에서 결정됩니다.
                
                스택 크기를 충분히 크게 설정하지 않으면, 스택 오버플로우(Stack Overflow)와 같은 문제가 발생할 수 있습니다. 반대로, 스택 크기를 지나치게 크게 설정하면 메모리 낭비가 발생할 수 있으므로 적절한 스택 크기 설정이 필요합니다.
                
        4. 왜 Stack이 heap 보다 빠르냐?
            - Stack이 heap보다 빠른 이유는 다음과 같습니다.
                1. Stack은 메모리 할당 및 해제가 빠릅니다.
                Stack은 데이터를 메모리 상단에 쌓는 방식으로 작동합니다. 이는 메모리를 먼저 할당하고 먼저 해제하는 것을 의미합니다. 반면, heap은 메모리를 할당 및 해제하는 데 시간이 더 걸리므로 Stack보다 느릴 수 있습니다.
                2. Cache hit rate가 더 높습니다.
                Stack은 데이터를 메모리 상단에 쌓는 방식으로 작동하므로, 스택에서 데이터를 읽어오는 데 걸리는 시간이 heap에서 데이터를 읽어오는 데 걸리는 시간보다 짧을 가능성이 높습니다. 이는 cache hit rate가 더 높아지고 프로그램 성능이 향상될 수 있습니다.
                3. 메모리 조각화를 방지합니다.
                Stack은 데이터를 차례대로 쌓는 방식으로 작동하므로, 메모리 조각화를 방지할 수 있습니다. 반면, heap은 할당 및 해제하는 데이터 크기가 다양하여 메모리 조각화 문제가 발생할 가능성이 높습니다.
                
                그러나 heap이 필요한 상황도 있습니다. 예를 들어, 동적으로 크기가 변하는 데이터를 저장할 때 heap을 사용합니다. 따라서 프로그래머는 알맞은 상황에서 적절한 메모리 할당 방법을 선택해야 합니다.
                
    - 프로세스 상태에는 어떤 것들이 있나요?
        1. non-preemptive 에서 있을 수 없는 상태변화
            - Non-preemptive(비선점형) 스케줄링에서는 프로세스가 CPU를 스스로 내어놓을 때까지 다른 프로세스가 실행될 수 없습니다. 이는 프로세스가 실행 중에 다른 프로세스가 간섭할 수 없다는 것을 의미합니다. 따라서 Non-preemptive 스케줄링에서는 다음과 같은 상태 변화가 발생하지 않습니다.
                1. Running to Ready: Non-preemptive 스케줄링에서는 프로세스가 CPU를 스스로 내어놓을 때까지 다른 프로세스가 실행될 수 없으므로 Running 상태에서 Ready 상태로 바뀌는 경우는 없습니다.
                2. Blocked to Ready: Blocked 상태에서 Ready 상태로 바뀌는 경우는 발생할 수 있지만, Non-preemptive 스케줄링에서는 이러한 상태 변화가 발생하지 않습니다. Blocked 상태에서 Ready 상태로 바뀌는 경우는, 입출력 작업이 끝나기 전에 프로세스가 대기열에서 다시 실행되도록 할 때 사용됩니다.
                
                따라서, Non-preemptive 스케줄링에서는 Running 상태에서 다른 상태로 바뀌는 경우는 없으며, Blocked 상태에서 Ready 상태로 바뀌는 경우도 드물게 발생합니다.
                
        2. Memory가 부족할 경우, Process는 어떠한 상태로 변하는가
            - Memory가 부족할 경우, 운영체제는 메모리 부족 상황을 해결하기 위해 다음과 같은 조치를 취합니다.
                1. Swapping: 운영체제는 현재 메모리에 있는 프로세스 중 일부를 디스크로 Swap out(메모리에서 디스크로 이동)합니다. 이를 통해 더 많은 메모리 공간을 확보할 수 있습니다. Swap out된 프로세스는 디스크에서 다시 메모리로 Swap in(디스크에서 메모리로 이동)될 때까지 실행되지 않습니다.
                2. Page Fault: 메모리에 적재된 프로세스에서 필요한 페이지가 메모리에 없는 경우, Page Fault가 발생합니다. 이 경우 운영체제는 디스크에서 해당 페이지를 가져와 메모리에 적재합니다.
                3. Kill Process: 메모리 부족 상황이 심각한 경우, 운영체제는 메모리를 많이 사용하는 프로세스 중 일부를 강제 종료합니다. 이를 통해 메모리를 확보할 수 있습니다.
                
                따라서, 메모리가 부족한 상황에서는 운영체제가 위와 같은 조치를 취하게 됩니다. 이에 따라 실행 중인 프로세스는 Swap out, Page Fault, 혹은 강제 종료될 수 있습니다. 이러한 상황에서는 프로세스의 실행이 지연될 수 있으므로, 메모리 사용량을 최적화하는 것이 중요합니다.
                
    - 좀비 프로세스, 고아 프로세스
        - 
            
            좀비 프로세스(Zombie Process)는 프로세스가 종료되었지만, 해당 프로세스의 상태 정보가 여전히 시스템에서 남아있는 상태를 말합니다. 일반적으로 자식 프로세스가 부모 프로세스에게 종료 상태를 알리기 위해 사용하는 wait() 시스템 호출을 부모 프로세스가 제때 처리하지 않아 발생합니다. 부모 프로세스는 자식 프로세스의 상태를 확인하고 메모리를 해제해주어야 하는데, 이를 하지 않으면 해당 프로세스는 좀비 프로세스로 남아있게 됩니다. 좀비 프로세스는 메모리 자원을 차지하고 있으므로, 시스템 성능에 영향을 미칠 수 있습니다.
            
            고아 프로세스(Orphan Process)는 부모 프로세스가 종료되거나 다른 이유로 인해 부모 프로세스와의 연결이 끊어진 상태인 프로세스를 말합니다. 이러한 상태에서는 자식 프로세스가 부모 프로세스에게 종료 상태를 알릴 수 없습니다. 이 경우 운영체제는 자식 프로세스를 새로운 부모 프로세스를 지정하여 계속 실행시킵니다. 고아 프로세스는 일반적으로 운영체제가 자동으로 처리하여 해결합니다. 운영체제는 고아 프로세스를 새로운 부모 프로세스에게 할당하고, 해당 프로세스가 종료될 때까지 관리합니다.
            
            좀비 프로세스와 고아 프로세스는 모두 부모 프로세스와 자식 프로세스 간의 연결이 끊어져 있지만, 좀비 프로세스는 부모 프로세스에서 wait() 호출을 처리하지 않은 상태에서 남아있는 반면에, 고아 프로세스는 운영체제에서 새로운 부모 프로세스를 지정하여 처리됩니다.
            
        1. sub reaper
            - subreaper는 리눅스 운영 체제에서 프로세스 관리 기능을 개선하는 기술입니다.
                
                일반적으로 부모 프로세스는 자식 프로세스가 종료될 때 그것의 상태를 처리합니다. 그러나 subreaper는 이런 부모-자식 프로세스 관계를 더욱 다양하게 처리할 수 있게 해줍니다.
                
                subreaper가 있는 시스템에서는 subreaper 프로세스가 부모 프로세스의 역할을 수행합니다. 이렇게 하면 자식 프로세스가 종료될 때 그것의 상태를 subreaper 프로세스에서 처리하고, 부모 프로세스에서는 그것을 신경쓰지 않아도 됩니다.
                
                이러한 기술은 특히 자식 프로세스가 데몬으로 실행되는 경우에 유용합니다. 데몬 프로세스는 종종 부모 프로세스가 종료될 때 자식 프로세스의 상태를 처리하지 않기 때문입니다. subreaper를 사용하면 데몬 프로세스가 안정적으로 동작할 수 있게 됩니다.
                
                subreaper는 리눅스 커널 버전 3.4부터 도입되었습니다. 이를 사용하려면 프로세스를 생성할 때 CLONE_CHILD_SUBREAPER 플래그를 설정해야 합니다.
                
            - 데몬이란?
                
                데몬(daemon)은 리눅스나 유닉스 운영 체제에서 백그라운드(background)에서 실행되는 프로세스를 일컫습니다. 데몬은 일반적으로 시스템 서비스를 제공하거나, 주기적으로 실행되는 작업을 수행하거나, 특정 이벤트를 감지하고 처리하는 등의 역할을 수행합니다.
                
                데몬은 일반적으로 터미널과 같은 인터랙티브 쉘(interactive shell)에서 실행되는 프로세스와는 달리 백그라운드에서 실행되기 때문에, 사용자 입력을 받지 않고 파일 입출력 등의 작업을 수행할 때 유용합니다. 또한, 데몬은 시스템 부팅시 자동으로 시작되는 서비스로 등록되어 시스템이 재시작되더라도 자동으로 실행되어 서비스 제공의 지속성을 보장합니다.
                
                예를 들어, 웹 서버나 데이터베이스 서버와 같은 시스템 서비스는 데몬으로 실행됩니다. 이러한 데몬들은 사용자 입력을 받지 않고, 백그라운드에서 지속적으로 실행되어 요청을 처리하거나 데이터베이스 작업을 수행합니다.
                
            
    
2. 멀티 프로세스와 멀티 스레드에 대해 설명해주세요.
    1. 멀티 스레드랑 싱글 스레드 차이
        - 
            
            싱글 스레드는 한 번에 하나의 작업만 처리할 수 있는 방식입니다. 이는 순차적으로 작업을 처리하는 방식으로, 하나의 작업을 처리할 때까지 다른 작업은 대기해야 합니다. 예를 들어, 웹 브라우저가 싱글 스레드로 작동한다면, 하나의 웹 페이지를 로드할 때까지 다른 작업은 수행할 수 없습니다.
            
            반면 멀티 스레드는 동시에 여러 작업을 처리할 수 있는 방식입니다. 멀티 스레드 방식을 사용하면 여러 개의 스레드가 동시에 작업을 수행하며, 작업이 끝나는 대로 결과를 모아서 처리합니다. 이를 통해 처리 속도를 높일 수 있습니다.
            
            멀티 스레드 방식은 여러 스레드가 공유하는 데이터나 자원의 동기화 이슈에 대한 관리가 필요합니다. 이를 위해 적절한 동기화 기술을 사용하여 여러 스레드가 안전하게 데이터나 자원을 공유하도록 해야 합니다.
            
            또한, 멀티 스레드는 여러 스레드가 동시에 작업을 수행하기 때문에, 스레드 간의 우선순위 설정과 작업 분배 등의 세부적인 관리도 필요합니다.
            
            결론적으로, 싱글 스레드와 멀티 스레드 방식은 프로그래밍의 목적과 상황에 따라 선택해야 합니다. 작업 처리 속도를 높이기 위해서는 멀티 스레드 방식을 사용할 수 있지만, 자원 공유나 동기화 이슈 등에 대한 관리도 함께 고려해야 합니다.
            
    2. 각각의 종류가 유리한 경우와 종류
        - 
            
            1. **단순히 CPU만을 사용하는 계산작업이라면, 오히려 멀티스레드보다 싱글스레드로 프로그래밍하는 것이 더 효율적이다.**
            
            멀티 스레드와 싱글 스레드 방식은 각각의 상황에 따라 유리한 경우가 다릅니다.
            
            싱글 스레드 방식은 작업을 순차적으로 처리하는 방식이기 때문에, 작업 처리 순서가 중요한 경우에 유리합니다. 예를 들어, 단순한 계산이나 I/O 작업이 많지 않은 프로그램에서는 싱글 스레드 방식이 효율적일 수 있습니다. 또한, 프로그래밍이 간단하고 프로그램의 크기가 작을 경우에도 싱글 스레드 방식이 편리합니다.
            
            반면, 멀티 스레드 방식은 여러 작업을 동시에 처리해야 하는 경우에 유리합니다. 예를 들어, 대용량 데이터 처리나 병렬 작업 처리와 같은 경우에 멀티 스레드 방식을 사용하면 작업 처리 속도를 효과적으로 높일 수 있습니다. 또한, GUI(GUI(Graphical User Interface))나 네트워크 프로그래밍에서는 멀티 스레드 방식을 사용해야만 사용자의 입력과 같은 다양한 이벤트를 처리할 수 있습니다.
            
    3. 오버헤드가 발생하는 이유
        - 
            
            멀티 스레드에서 오버헤드가 발생하는 주요 이유는 다음과 같습니다.
            
            1. 스레드 생성 및 종료
            
            스레드를 생성하고 종료하는 과정에서 오버헤드가 발생합니다. 스레드를 생성하면 스레드마다 독립적인 스택과 다른 자원을 할당해야 하기 때문입니다. 또한, 스레드 종료 시에는 할당된 자원을 해제해야 하기 때문에 오버헤드가 발생할 수 있습니다.
            
            1. 스레드 간의 동기화
            
            멀티 스레드에서는 스레드 간에 공유하는 자원에 대한 접근이 동시에 일어날 수 있습니다. 이 때, 스레드 간의 동기화를 위해 락(lock)을 사용하면 락을 획득하거나 해제하는 과정에서 오버헤드가 발생할 수 있습니다. 또한, 데드락(deadlock)이 발생할 가능성도 있습니다.
            
            1. 캐시 일관성 문제
            
            멀티 코어 CPU에서는 캐시 일관성 문제가 발생할 수 있습니다. 캐시 일관성 문제란, 여러 개의 CPU 코어가 동일한 메모리 위치에 접근할 때, 각 코어의 캐시에 저장된 데이터가 서로 다르게 되는 문제입니다. 이 경우, CPU 간에 메모리를 동기화하는 데 시간이 소요되므로 오버헤드가 발생할 수 있습니다.
            
            1. 스레드 간 컨텍스트 스위칭
            
            멀티 스레드에서는 스레드 간에 실행 시간을 분할하여 작업을 수행하기 때문에, 스레드 간에 컨텍스트 스위칭이 일어납니다. 컨텍스트 스위칭은 CPU가 한 스레드에서 다른 스레드로 작업을 전환하는 과정을 말하며, 이 때 오버헤드가 발생할 수 있습니다.
            
            이러한 멀티 스레드에서의 오버헤드는 프로그램이 복잡해지면 더욱 심화되며, 이를 최소화하기 위해서는 적절한 스레드 개수 설정, 락(lock)의 사용 최소화, 캐시 일관성 문제를 줄이는 기법 등을 적용하여 최적화를 수행하는 것이 필요합니다.
            
    4. 그럼 웹서버가 이러한 상태일 때는 스레드가 좋아 프로세스가 좋아? 이유는?
        - 
            
            웹 서버에서는 클라이언트의 요청을 처리하기 위해 여러 가지 작업이 필요합니다. 이 작업은 I/O 작업(네트워크 입출력)과 CPU 작업(요청 처리)으로 구분됩니다. 이러한 작업을 처리하는 데 있어서, 스레드와 프로세스 각각의 장단점이 존재합니다.
            
            스레드를 사용하는 경우, 하나의 프로세스 내에서 여러 개의 스레드를 생성하여 작업을 처리합니다. 이 때, 스레드는 프로세스 내의 메모리를 공유하므로 스레드 간 데이터 전달이 용이하며, 스레드 간의 전환 작업에서 발생하는 오버헤드가 적습니다. 또한, 스레드의 생성 및 종료가 프로세스보다 빠르므로, 클라이언트 요청에 대한 응답 속도가 빠릅니다. 따라서, 웹 서버에서 I/O 작업이 많은 경우에는 스레드를 사용하는 것이 유리합니다.
            
            반면에, 프로세스를 사용하는 경우, 각각의 프로세스는 독립적인 메모리 공간을 가지므로, 각각의 프로세스가 독립적으로 작업을 처리할 수 있습니다. 따라서, CPU 작업이 많은 경우에는 프로세스를 사용하는 것이 유리합니다.
            
            하지만, 프로세스를 생성하면, 스레드를 생성하는 것보다 더 많은 자원이 소모되므로, 많은 수의 클라이언트 요청을 처리하기에는 제한이 있습니다. 또한, 프로세스 간 통신(IPC)을 위해서는 별도의 메커니즘이 필요하므로 구현이 복잡해집니다.
            
            따라서, 웹 서버에서는 I/O 작업이 많은 경우에는 스레드를 사용하는 것이 일반적이지만, CPU 작업이 많은 경우에는 프로세스를 사용하는 것이 적절할 수 있습니다.

---
## PCB에 대해 설명해주세요.
PCB에 대해 설명해주세요.

- PCB(Process Control Block)는 운영체제가 각각의 프로세스를 관리하기 위해 유지하는 정보 블록입니다. 각각의 프로세스마다 하나씩 존재하며, 프로세스의 상태 정보를 저장하고, 프로세스 간 전환이 일어날 때 해당 정보를 업데이트합니다.
    
    PCB는 크게 다음과 같은 정보를 포함합니다.
    
    1. 프로세스 식별자(Process ID, PID) : 프로세스를 구분하기 위한 고유한 식별자
    2. 프로세스 상태 : 현재 프로세스가 실행중인지, 대기 중인지, 중지된 상태인지 등의 상태 정보
    3. 프로그램 계수기(Program Counter, PC) : 다음에 실행될 명령어의 주소 정보
    4. 레지스터 정보 : 프로세스가 실행되는 동안 사용되는 레지스터의 값 정보
    5. 스케줄링 정보 : 프로세스의 우선순위, 스케줄링 알고리즘 등의 정보
    6. 메모리 관리 정보 : 프로세스가 사용하는 메모리 주소 정보, 페이지 테이블 등의 정보
    7. 입출력 상태 정보 : 현재 프로세스가 사용 중인 입출력 장치 정보, 입출력 대기 큐 등의 정보
    
    PCB는 각각의 프로세스에 대해 유지되므로, 프로세스의 상태 정보를 기억하고 다음 실행을 위한 정보를 보관하며, 다른 프로세스로의 전환이 필요할 때 해당 정보를 활용합니다. 또한, PCB는 다중 프로그래밍 환경에서 각각의 프로세스를 안정적으로 관리하고, 우선순위나 중요도 등을 고려하여 스케줄링하는 데 중요한 역할을 합니다.
    

- 스레드는 PCB를 갖고 있을까요?
    - 네, 스레드(Thread)도 PCB(Process Control Block)를 갖고 있습니다.
        
        스레드는 프로세스 내에서 실행되는 작은 단위의 실행 흐름으로, 프로세스의 자원을 공유합니다. 그러므로 스레드도 각각의 실행 상태 정보를 관리하기 위한 PCB를 갖고 있습니다.
        
        스레드의 PCB에는 프로세스 PCB와 유사한 정보가 저장됩니다. 하지만, 스레드는 프로세스 내에서 생성되므로, 프로세스 PCB와는 다르게, 스레드 ID(Thread ID)와 같은 추가적인 정보가 포함될 수 있습니다. 또한, 스레드의 PCB에는 스레드의 우선순위, 스케줄링 정보 등 스레드 관련 정보가 포함됩니다.
        
        스레드는 프로세스 내에서 실행되는 작은 실행 흐름이므로, 스레드의 PCB는 프로세스 PCB와 달리, 스레드 간의 전환이 더 빠르고 경량화된 구조를 갖는 경우가 있습니다. 이는 스레드가 프로세스 내에서 생성되고 실행되는 것 때문입니다.
        
- 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
    - 
        
        자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면, 해당 프로세스는 좀비 프로세스(Zombie Process)가 됩니다. 좀비 프로세스는 프로세스가 종료된 후, 해당 프로세스의 정보가 완전히 삭제되기 전까지 남아있는 상태입니다.
        
        좀비 프로세스는 시스템의 자원을 차지하므로, 가능한 빨리 종료되어야 합니다. 이를 위해 운영체제는 부모 프로세스에게 SIGCHLD 시그널을 보내어, 자식 프로세스가 종료되었음을 알리고, 해당 자식 프로세스의 정보를 삭제하도록 합니다. 따라서 부모 프로세스는 wait()나 waitpid()와 같은 시스템 호출을 통해 자식 프로세스의 상태를 확인하고, 해당 자식 프로세스의 정보를 삭제할 수 있습니다.
        
        하지만, 부모 프로세스가 이미 종료된 경우, 자식 프로세스는 init 프로세스의 자식 프로세스가 되며, init 프로세스는 SIGCHLD 시그널을 받아 처리합니다. 따라서, 운영체제는 이러한 과정을 통해 좀비 프로세스를 종료시킵니다.
        
- 프로세스 주소공간에 대해 설명해 주세요.
    - 프로세스 주소 공간(Process Address Space)은 프로세스가 실행되기 위해 필요한 메모리 공간입니다. 각각의 프로세스는 자신만의 독립적인 주소 공간을 가지며, 이는 다른 프로세스의 주소 공간과 격리되어 있습니다.
        
        프로세스 주소 공간은 크게 코드 영역, 데이터 영역, 스택 영역으로 나뉩니다.
        
        1. 코드(Code) 영역 : 프로그램 코드가 저장되는 공간으로, 실행 가능한 명령어들이 위치합니다. 이 영역은 읽기 전용으로 보호되어 있습니다.
        2. 데이터(Data) 영역 : 전역 변수, 정적 변수, 초기화된 데이터 등이 저장되는 공간입니다. 이 영역은 읽기 쓰기가 가능합니다.
        3. 스택(Stack) 영역 : 함수 호출 시 생성되는 지역 변수, 매개 변수, 리턴 값 등이 저장되는 공간입니다. 스택은 후입선출(LIFO, Last In First Out) 방식으로 동작하며, 새로운 스택 프레임(Stack Frame)이 생성될 때마다 스택 포인터(Stack Pointer)가 이동합니다.
        
        또한, 프로세스 주소 공간에는 힙(Heap) 영역도 존재합니다. 힙 영역은 동적으로 메모리를 할당받는 공간으로, malloc(), new() 등의 함수를 사용하여 할당됩니다.
        
        프로세스 주소 공간은 가상 주소 공간(Virtual Address Space)으로 구성되어 있습니다. 이는 프로세스가 사용하는 실제 물리적인 주소와는 별개로, 프로세스가 인식하는 주소입니다. 가상 주소 공간을 사용하면 여러 프로세스가 서로 독립적으로 실행될 수 있고, 메모리 주소를 보호하거나 공유하는 등의 기능을 수행할 수 있습니다.
        
    - 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
        - 
            
            프로세스의 스택과 힙의 크기는 일반적으로 그렇게 크지 않습니다. 이 크기는 프로그램의 특성과 사용되는 데이터에 따라 달라지며, 프로그램이 실행될 때 런타임에 결정됩니다.
            
            프로세스의 스택 크기는 일반적으로 스레드 수, 재귀 함수 호출 수 등의 요소에 따라 결정됩니다. 스택의 크기는 프로그램의 컴파일러나 링커 등에서 설정할 수 있으며, 보통 기본값이 설정되어 있습니다. 하지만 프로그램이 실행될 때 런타임에 필요한 만큼의 스택이 할당되며, 필요에 따라 스택 크기를 동적으로 조정할 수도 있습니다.
            
            힙의 크기는 메모리 할당 함수(malloc, new 등)를 사용하여 동적으로 할당되는 메모리 크기에 따라 결정됩니다. 프로그램이 실행될 때는 힙의 크기가 결정되어 있지 않으며, 메모리가 필요한 시점에 동적으로 할당됩니다. 따라서, 힙의 크기는 프로그램의 동작 중에 계속해서 변할 수 있습니다.
            
            종합적으로, 프로세스의 스택과 힙의 크기는 프로그램이 실행될 때 결정되며, 이는 프로그램의 특성과 사용되는 데이터에 따라 다양하게 변할 수 있습니다.
            
    - Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
        - 
            
            스택(Stack)과 힙(Heap)은 모두 동적 메모리 할당을 위한 공간이지만, 접근 속도가 다릅니다. 일반적으로 스택이 힙보다 접근 속도가 더 빠릅니다.
            
            스택은 프로세스 실행 중 함수 호출이 발생하면 생성되며, 마지막에 호출된 함수가 먼저 반환되기 때문에 후입선입(LIFO) 구조를 가지고 있습니다. 이 구조는 메모리 캐시(cache)를 이용한 메모리 접근 기술에서 큰 이점을 가져옵니다. 함수 호출 시 스택 프레임(stack frame)이 생성되는데, 이는 CPU 캐시에 많은 정보를 저장하여 CPU가 쉽게 접근할 수 있도록 합니다.
            
            반면, 힙은 동적으로 메모리를 할당하고 해제하므로, 스택과는 달리 메모리 블록이 불규칙하게 위치하며, 여러 스레드에서 동시에 접근할 수 있습니다. 따라서, 메모리 캐시를 이용한 메모리 접근 기술에서는 스택보다 성능이 떨어질 수 있습니다.
            
            종합적으로, 스택이 힙보다 접근 속도가 더 빠르므로, 가능하다면 스택을 이용하여 변수를 할당하고 사용하는 것이 좋습니다. 그러나 스택은 함수 호출 시 생성되므로, 스택의 크기가 제한되어 있습니다. 반면에 힙은 동적 메모리 할당을 통해 크기가 자유롭게 조절될 수 있으며, 여러 스레드에서 공유할 수 있으므로, 스택과는 다른 용도로 사용됩니다.
            
    - 다음과 같이 공간을 분할하는 이유가 있을까요?
        - 메모리 공간을 코드, 데이터, 힙, 스택으로 분할하는 이유는 다음과 같습니다.
            1. 보안
            
            코드 영역과 데이터 영역은 읽기 전용이므로, 프로그램 실행 중에 코드나 데이터가 변경되는 것을 방지할 수 있습니다. 이를 통해 보안 측면에서 프로그램을 안전하게 실행할 수 있습니다.
            
            1. 메모리 관리
            
            힙과 스택은 모두 동적 메모리 할당을 위한 공간입니다. 그러나 스택은 후입선입(LIFO) 구조를 가지고 있으므로, 메모리 할당과 해제가 빠르고 효율적입니다. 반면 힙은 메모리 블록이 불규칙하게 위치하므로, 메모리 할당과 해제가 느리고 복잡합니다.
            
            1. 성능
            
            메모리 영역을 분할하면 프로그램의 성능을 최적화할 수 있습니다. 코드 영역과 데이터 영역은 읽기 전용이므로, CPU가 빠르게 접근할 수 있습니다. 반면 힙은 동적으로 메모리를 할당하고 해제하기 때문에, 스택과는 달리 접근 속도가 느릴 수 있습니다.
            
            1. 오류 방지
            
            스택 오버플로우(Stack Overflow)는 스택이 할당된 크기를 초과하여 발생하는 오류입니다. 스택 오버플로우는 프로그램이 비정상적으로 종료되거나 보안 취약점을 유발할 수 있습니다. 메모리 영역을 분할하면, 스택의 크기를 제한할 수 있어 스택 오버플로우를 방지할 수 있습니다.
            
            따라서, 메모리 공간을 코드, 데이터, 힙, 스택으로 분할하는 것은 프로그램 실행의 안정성, 보안성, 성능, 메모리 관리 등 다양한 측면에서 이점이 있습니다.
            
    - 스레드의 주소공간은 어떻게 구성되어 있을까요?
        - 
            
            스레드는 프로세스 내에서 실행되는 작은 단위의 실행 흐름이며, 프로세스와는 별개로 고유한 주소 공간을 갖지 않습니다. 스레드는 프로세스의 주소 공간을 공유하며, 스레드가 생성될 때 스택 영역을 제외한 나머지 영역은 공유됩니다.
            
            따라서, 스레드는 코드 영역, 데이터 영역, 힙 영역을 비롯한 모든 공유 자원에 대한 접근 권한을 가집니다. 그리고 스레드는 자신만의 스택 영역을 가지고 있으며, 이 스택 영역은 해당 스레드에서 호출되는 함수의 매개변수, 지역 변수, 복귀 주소 등을 저장하는 데 사용됩니다.
            
            따라서, 스레드의 주소 공간은 프로세스의 주소 공간과 거의 동일하며, 스레드가 실행하는 함수의 매개변수와 지역 변수 등은 스레드의 스택 영역에 저장됩니다. 스레드는 공유 메모리를 통해 다른 스레드와 데이터를 공유할 수 있으므로, 이를 제어하기 위한 동기화 기술이 필요합니다.
            

**컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?**

- 컨텍스트 스위칭은 언제 일어날까요?
    - 
        
        컨텍스트 스위칭은 운영체제가 여러 프로세스나 스레드를 동시에 실행하면서, 하나의 프로세스나 스레드가 다른 프로세스나 스레드에게 CPU 사용권을 양도할 때 발생합니다. 이러한 양도는 다음과 같은 상황에서 일어납니다.
        
        1. 인터럽트: 하드웨어나 소프트웨어적인 인터럽트가 발생하면, 현재 실행중인 프로세스나 스레드의 실행이 중단되고 인터럽트 처리를 위한 인터럽트 핸들러가 실행됩니다. 이때, 인터럽트 핸들러가 실행되는 동안 다른 프로세스나 스레드가 CPU를 사용할 수 있습니다.
        2. 시간 할당량 만료: 운영체제는 각 프로세스나 스레드에게 CPU를 일정 시간만큼 할당하고, 그 시간이 다 되면 해당 프로세스나 스레드는 CPU를 반납하고 다른 프로세스나 스레드에게 양도됩니다.
        3. 입출력 완료: 입출력 작업을 실행하는 동안 프로세스나 스레드는 대기 상태가 되고, 다른 프로세스나 스레드가 CPU를 사용할 수 있습니다. 입출력 작업이 완료되면, 해당 프로세스나 스레드는 다시 실행됩니다.
        
        컨텍스트 스위칭은 위와 같은 상황에서 일어나며, 이때 운영체제는 현재 실행중인 프로세스나 스레드의 상태를 저장하고, 다음 실행할 프로세스나 스레드의 상태를 복원합니다. 이러한 작업은 CPU 시간과 자원을 소모하기 때문에, 컨텍스트 스위칭이 자주 발생하면 시스템 성능에 영향을 미칠 수 있습니다. 따라서, 운영체제는 효율적인 스케줄링 알고리즘을 사용하여 컨텍스트 스위칭의 빈도를 최소화하고, 시스템 성능을 향상시키기 위한 노력을 합니다.
        
- 프로세스와 쓰레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
    - 
        
        프로세스와 스레드는 모두 실행 중인 상태에서 다른 프로세스나 스레드로 전환될 때 컨텍스트 스위칭이 발생합니다. 그러나 두 가지 유형의 컨텍스트 스위칭에는 중요한 차이점이 있습니다.
        
        먼저, 프로세스의 컨텍스트 스위칭은 더 많은 오버헤드를 발생시킵니다. 이는 프로세스 간에 메모리를 공유하지 않으므로, 실행 중인 프로세스의 주소 공간을 모두 저장하고, 실행 중인 스레드의 레지스터 상태를 저장하고, 새로운 프로세스의 주소 공간을 로드하고, 해당 프로세스에서 실행할 스레드의 초기 레지스터 값을 설정해야 하기 때문입니다. 이러한 작업은 많은 시간과 CPU 자원을 소비하게 됩니다.
        
        한편, 스레드의 컨텍스트 스위칭은 프로세스의 컨텍스트 스위칭보다 훨씬 더 빠릅니다. 이는 스레드들이 하나의 주소 공간을 공유하기 때문입니다. 스레드 간에는 스택과 레지스터 상태만 변경되므로, 프로세스의 컨텍스트 스위칭보다 훨씬 덜 오버헤드가 발생합니다.
        
        따라서, 스레드를 사용하면 프로세스보다 더 빠르고 효율적인 멀티태스킹이 가능하며, 메모리와 자원의 효율성을 높일 수 있습니다.
        

- 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?


---
## 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?
- 컨텍스트 스위칭은 CPU가 하나 이상의 프로세스를 처리할 때 발생합니다. 이때 현재 실행 중인 프로세스의 상태를 보관하고, 다음 실행할 프로세스의 상태를 불러오는 작업이 수행됩니다. 이는 CPU의 처리 시간을 분할하여 여러 프로세스가 동시에 실행될 수 있도록 하기 위해 필요합니다.

  ### Q) 컨텍스트 스위칭은 언제 일어날까요?
  - 프로세스와 스레드는 모두 실행 중인 프로그램의 단위입니다. 하지만 컨텍스트 스위칭(Context Switching)에 대한 처리 방식에서 차이가 있습니다.
  프로세스는 각각 독립된 메모리 공간을 가지고 있기 때문에, 프로세스 간 컨텍스트 스위칭이 발생하면, 현재 실행 중인 프로세스의 상태 정보를 PCB(Process Control Block)에 저장한 후, 새로운 프로세스의 PCB로 전환하여 해당 프로세스를 실행합니다. 이는 새로운 프로세스가 시작되는 것과 동일합니다.
스레드는 하나의 프로세스 내에서 실행되기 때문에, 컨텍스트 스위칭이 발생하면, 스레드 간의 스택, 레지스터 값 등의 상태 정보만 전환하면 됩니다. 따라서, 스레드 간의 컨텍스트 스위칭은 프로세스 간의 컨텍스트 스위칭보다 훨씬 빠릅니다.


  ### Q) 프로세스와 쓰레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
  - 프로세스와 쓰레드는 모두 컨텍스트 스위칭이 발생했을 때 다음에 실행할 코드와 상태를 저장하고 복원하는 작업이 필요합니다. 하지만 그들 간에 컨텍스트 스위칭에는 몇 가지 차이점이 있습니다.

    프로세스는 운영 체제에서 독립적인 실행 단위입니다. 프로세스 간에는 각자의 독립적인 가상 메모리 공간이 할당되며, 이러한 가상 메모리 공간은 다른 프로세스에서 접근할 수 없습니다. 따라서 프로세스 간에는 데이터를 공유하기 위해 명시적인 IPC(Inter-Process Communication) 메커니즘이 필요합니다. 프로세스 간에 컨텍스트 스위칭이 발생하면, 현재 실행 중인 프로세스의 상태와 가상 메모리 정보가 저장되고, 다음 실행할 프로세스의 상태와 가상 메모리 정보가 복원됩니다.

    반면에 쓰레드는 하나의 프로세스 내에서 실행되는 실행 단위입니다. 쓰레드는 동일한 가상 메모리 공간을 공유하므로, 데이터 공유에 대한 별도의 IPC 메커니즘이 필요하지 않습니다. 쓰레드 간에 컨텍스트 스위칭이 발생하면, 현재 실행 중인 쓰레드의 상태가 저장되고, 다음 실행할 쓰레드의 상태가 복원됩니다.

    따라서, 프로세스와 쓰레드 간의 가장 큰 차이점은 가상 메모리 공간을 공유하는지 여부입니다. 프로세스는 독립적인 실행 단위이기 때문에, 프로세스 간에는 데이터 공유를 위해 별도의 IPC 메커니즘이 필요합니다. 쓰레드는 하나의 프로세스 내에서 실행되는 실행 단위이므로, 데이터 공유를 위한 IPC 메커니즘이 필요하지 않습니다.
 
  ### Q) 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?
  - 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 PCB(Process Control Block)라는 구조체에 저장됩니다. 이 구조체에는 프로세스의 상태, 레지스터 값, 실행 위치 등의 정보가 저장되며, PCB는 커널스택에 저장됩니다. 다음에 실행될 프로세스의 PCB가 커널스택에서 불러와지고, 해당 프로세스의 상태가 복원됩니다.

  
---
## 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?
- 프로세스 스케줄링 알고리즘에는 다양한 알고리즘이 있지만, 일반적으로 다음과 같은 알고리즘이 사용됩니다.
  
		FCFS(First-Come, First-Served) : 먼저 도착한 프로세스가 먼저 실행되는 알고리즘입니다.
		SJF(Shortest Job First) : 실행 시간이 가장 짧은 작업을 우선적으로 처리하는 알고리즘입니다.
		Priority Scheduling : 우선순위가 높은 작업을 먼저 실행하는 알고리즘입니다.
		Round-Robin : 각 프로세스가 일정 시간 동안 CPU를 할당받고, 시간이 지나면 다른 프로세스에게 CPU를 넘겨주는 알고리즘입니다.
		Multilevel Queue : 프로세스를 여러 개의 큐로 나누어 각 큐마다 다른 스케줄링 알고리즘을 적용하는 알고리즘입니다.
		Multilevel Feedback Queue : Multilevel Queue 알고리즘과 비슷하지만, 각 큐에서 실행되는 프로세스의 우선순위를 동적으로 변경해줍니다.
    이 외에도 다양한 스케줄링 알고리즘이 있으며, 실제 운영체제에서는 이러한 알고리즘들을 조합하여 최적화된 스케줄링을 수행합니다.
  
  ### Q) Preemptive / Non-Preemptive
  - Preemptive(선점형) 스케줄링과 Non-preemptive(비선점형) 스케줄링은 프로세스 스케줄링에서 중요한 개념입니다.
    
    Preemptive 스케줄링은 운영체제가 CPU를 점유하고 있는 프로세스를 강제로 중지시키고 다른 프로세스에게 CPU를 할당할 수 있는 방식입니다. 이는 우선순위가 높은 프로세스나시간 할당량이 끝난 프로세스 등이 다른 프로세스에게 CPU를 빠르게 양도할 수 있게 해줍니다.
    
    Non-preemptive 스케줄링은 한 프로세스가 CPU를 점유하는동안 다른 프로세스는 대기해야 합니다. CPU를 점유하는 프로세스가 종료되거나 대기 상태로 들어가야만 다른 프로세스가 CPU를 사용할 수 있습니다.
    
    Preemptive 스케줄링은 Non-preemptive 스케줄링보다 우선순위나 프로세스 상태 변화 등을 더 빠르게 반영할 수 있으나, 컨텍	스트 스위칭이 자주 일어나게 되어 오버헤드가 발생할 수 있습니다. 반면 Non-preemptive 스케줄링은 컨텍스트 스위칭이 적게 발생하여 오버헤드가 적지만, 우선순위가 높은 프로세스가 대기할 때 다른 프로세스들이 CPU를 사용할 수 없으므로 성능 저하가 발생할 수 있습니다.
	
  ### Q) Multi-level feedback Queue가 왜 나왔는지?
  - Multi-level feedback Queue가 왜 나왔는지는, Multi-level Queue에 있습니다.
    Multi-level Queue는 각 큐가 서로 다른 우선순위를 갖고 있으며, 우선순위가 높은 큐에서부터 순차적으로 프로세스를 스케줄링합니다.
    이 방식은 우선순위가 높은 프로세스들이 빠르게 실행됩니다. 하지만, 이러한 방식에는 우선순위가 낮은 큐에서 대기 중인 프로세스들이 무한정 기다려야 할 수도 있기 때문에, 모든 프로세스가 공평하게 CPU 시간을 사용할 수 없는 문제가 있습니다.
    
    
    또한, 프로세스의 중요도가 정해지면, 한 큐에만 고정이되어 큐를 이동할 수 없기때문에 융퉁성이 떨어집니다.
    
    
    이점을 개선하기 위해 Multi-level feedback Queue가 나왔습니다.
    Multi-level feedback Queue는 Multil-level Queue처럼 여러 개의 우선순위를 가집니다. 하지만, 실행 중인 프로세스가 일정시간 이상 실행되면 우선순위가 낮은 큐로 이동하게 됩니다. 이렇게 함으로써, 실행 시간이 긴 프로세스도 적절한 시간 내에 CPU를 반납하게 되어 다른 프로세드들도 실행될 수 있게 됩니다.
 	
	![image](https://user-images.githubusercontent.com/87464794/226160744-907068d4-ca49-4791-a8b8-92a53f390986.png)

  ### Q) Linux의 Process Scheduling?
  - 리눅스에서의 Process Schdeuling은 커널 내부에서 담당하는 스케줄러에 의해 수행됩니다. 기본적으로 리눅스는 시분할 방식의 Round Robin 스케줄링 알고리즘을 사용하며, 다양한 스케줄링 알고리즘들이 존재합니다.
    Round Robin(RR) 스케줄링은 각 프로세스에게 일정 시간 할당량을 부여하고, 이 시간이 지나면 다음 프로세스에게 CPU를 넘기는 방식으로 동작합니다. 이 방법은 CPU 시간을 공정하게 분배하며, 응답 시간을 빠르게 유지할 수 있습니다.
    다른 스케줄링 방식에는 CFS, O(1) 스케줄러가 있습니다.
    
     O(1) 스케줄링은 우선순위가 높은 run queue에서 Active list(array)에 있는 task들은 할당된 time slice에 따라 실행된다. 그리고 시간이 지나면 즉, 모든 time silce가 끝나면, Expired list((array)로 이동된다. 그다음 우선순위의 run queue로 이동하여 동작을 반복한다.  
    이렇게 Active list에 있는 모든 task가 동작하면 이때 list의 전환이 일어난다. list는 포인터에 의해서만 접근할 수 있기 때문에 Active list의 포인터를 Expired list로 바꿔준다. 이때 Expired list는 Active list가 되고 비어있던 Active list는 Expired list가 되는 동작을 한다.
    ![image](https://user-images.githubusercontent.com/87464794/226161770-96e0923c-83da-49ed-ae33-a74ffb88af40.png)
    
    이렇게 전체 프로세스를 스캔하지 않고 다음 실행할 프로세스를 알 수 있기 때문에 프로세스의 수와 상관없이 O(1)의 실행 시간을 가질 수 있다.

    하지만, Expired list에서 너무 오래 기다린다면 Actvie queue로 이동할 수 있다.
    runqueue에서 real time 프로세서의 우선순위는 0 ~ 99번으로 부여했고, 일반 프로세서에 대해선 100 ~ 139번의 우선순위를 부여했다. (위 그림에선 반대다) 100 ~ 139를 -20 ~ 19로 nice value라고 지정했는데, 높은 우선순위(-20)를 받을수록 time silce값을 크게 배정했다. 
    이렇듯 우선순위(nice value)에 의해 time slice가 정해지니 낮은 우선순위를 가진 프로세스는 빈번하게 context swiching을 하게 된다. nice value에 의해 절대적으로 시간이 나눠지는 unfairness(불공평)이 발생할 수 있다.
    
    이런 문제 때문에 이런 우선순위와 time slice의 mapping을 고려한 현재의 scheduler인 CFS가 나왔다.
    
    CFS는 <linux/sched.h>에 정의된 struct sched_entity라는 스케줄러 단위 구조체를 사용해서 정보를 저장합니다. CFS의 기본 개념은 작업에 프로세서 시간을 제공할 때 밸런스(공평성)를 유지하는 것입니다. 즉, 프로세스에 공평한 양의 프로세서가 제공되어야 하는 것을 목표로 합니다.
    다른 작업에 비해 하나 이상의 작업에 공평한 양의 시간이 주어지지 않은 경우에는 작업 시간이 적게 지정된 작업에 실행 시간이 주어져야 한다는 것을 목표로 합니다. 즉, 성능과 공평성 간의 균형을 중시하는 스케쥴러입니다.
    
    CFS에서는 밸런스를 결정하기 위해 가상 런타임이라는 지정된 작업에 제공된 시간의 양을 관리합니다. 작업의 가상 런타임이 작을수록 즉, 프로세서에 액세스할 수 있도록 허용된 시간이 작은 작업일수록 더 많은 프로세서 시간이 필요합니다. 또한 CFS에는 대기자 공평성이라는 개념도 포함되어 있습니다. 이 개념은 현재 실행할 수 없는 작업이 나중에 프로세서가 필요할 때 대기했던 시간에 상응하는 프로세서 시간을 받을 수 있도록 보장합니다.
    
    즉, 프로세스의 우선순위를 직접적으로 ready queue의 정렬등을 하여 스케쥴링 하지는 않지만, runtime이 스케쥴링 연산에 고려되므로, vruntime이 스케쥴링에 영향을 미치게 됩니다.

  ### Q) RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.
  - (Trade-off 라는 용어를 먼저 설명하겠습니다) Trade-off는 서로 대립하는 두 가지 요소 중 하나를 선택하는 것이 나머지 하나를 포기하거나 희생하는 상황에서 양쪽 요소를 균형있게 고려하는 것을 말합니다. 예를 들면, 스마트폰 배터리 수명과 성능 사이에는 trade-off가 존재합니다. 배터리 수명을 높이려면, 성능을 희생해야 하고, 성능을 높이려면 배터리 수명이 줄어듭니다.
  - RR 스케줄링에서도 시간 할당량에 따른 trade-off가 있습니다. 예를 들어, 시간 할당량을 크게 설정하면, 프로세스는 더 많은 시간을 CPU에서 사용할 수 있어서 처리 속도가 빨라질 수 있지만, 다른 프로세스가 실행되기까지 대기하는 시간이 길어져서 응답 속도가 느려질 수 있습니다. 반대로, 시간 할당량을 작게 설정하면, 프로세스 간 교대로 실행하는 빈도가 높아져서 응답 속도가 빨라질 수 있지만, 많은 교대가 발생하게 되어 스케줄링 오버헤드가 커지고 처리 속도가 느려질 수 있습니다.
  
    따라서, 시간 할당량(Time Slice)을 선택하는 것은 trade-off의 문제입니다. 적절한 시간 할당량을 선택하면, 처리 속도와 응답 속도를 군형있게 유지할 수 있습니다.
    
  5. 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요
    - 
        
        싱글 스레드 CPU에서 상시로 돌아가야 하는 프로세스가 있다면, Round Robin 스케줄링 알고리즘이 적합할 수 있습니다.
        
        Round Robin 스케줄링은 시분할 시스템에서 사용되는 스케줄링 알고리즘으로, CPU 시간을 일정 크기의 단위로 분할하고, 각 프로세스에게 일정한 시간을 할당하는 방식입니다. 따라서, 상시로 돌아가야 하는 프로세스에게도 일정한 CPU 시간을 할당할 수 있습니다. 만약 해당 프로세스가 다른 프로세스보다 CPU 시간을 많이 사용해야 한다면, Round Robin 스케줄링의 시간 할당량을 적절하게 조정하여 처리할 수 있습니다.
        
        또한, Round Robin 스케줄링은 대화형 시스템에서 응답 시간을 보장하면서 다양한 프로세스를 처리할 수 있기 때문에, 상시로 돌아가야 하는 프로세스와 함께 다른 프로세스도 처리해야하는 경우에도 유용합니다.
        
        하지만, 만약 상시로 돌아가야 하는 프로세스가 다른 프로세스에 비해 CPU 사용량이 매우 높은 경우, Round Robin 스케줄링은 효율적이지 않을 수 있습니다. 이 경우, 우선순위 기반 스케줄링 알고리즘 등 다른 스케줄링 알고리즘을 고려해볼 수 있습니다.
        
6. 동시성과 병렬성의 차이에 대해 설명해 주세요.
    - 
        
        동시성(Concurrency)과 병렬성(Parallelism)은 컴퓨터 과학에서 매우 중요한 개념입니다. 둘 다 동시에 여러 작업을 처리하는 것을 의미하지만, 그 의미와 방법이 서로 다릅니다.
        
        동시성은 여러 작업이 동시에 실행되는 것처럼 보이지만, 실제로는 하나의 CPU에서 번갈아가며 처리됩니다. 즉, 여러 작업이 동시에 시작되고, 실행 중일 때 서로 간섭하지 않고 독립적으로 실행되며, 이 작업들의 진행 상황을 관리하는 방법입니다. 예를 들어, 여러 프로그램을 동시에 실행하는 경우, CPU가 각 프로그램을 번갈아가며 처리하면서 동시에 실행되는 것처럼 보일 수 있습니다. 하지만, 실제로는 CPU는 각 프로그램을 처리할 때마다 컨텍스트 스위칭(Context Switching)을 수행하여 프로그램 간의 전환이 일어나는 것입니다.
        
        반면에, 병렬성은 여러 작업을 동시에 실행하면서, 각 작업이 서로 영향을 미치지 않고 독립적으로 처리되며, 병렬 처리를 위해 여러 CPU나 코어 등의 시스템 자원이 사용됩니다. 예를 들어, 여러 스레드 또는 프로세스를 병렬적으로 실행하는 경우, 각 스레드 또는 프로세스가 독립적으로 처리됩니다. 이 경우, 병렬 처리를 위한 시스템 자원(예: 다중 코어, 다중 프로세서)이 필요합니다.
        
        따라서, 동시성과 병렬성은 다음과 같은 차이가 있습니다.
        
        - 동시성: 하나의 CPU에서 여러 작업이 번갈아가며 처리됩니다. 작업들은 동시에 시작되고, 실행 중일 때 서로 간섭하지 않고 독립적으로 실행됩니다.
        - 병렬성: 여러 CPU나 코어 등의 시스템 자원을 사용하여 여러 작업이 동시에 처리됩니다. 작업들은 서로 영향을 미치지 않고 독립적으로 처리됩니다.
7. 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?

단기, 중기, 장기 스케쥴러

1. 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?
    - 네, 현대 운영 체제에서는 단기, 중기 및 장기 스케줄러를 모두 사용합니다. 이들은 다음과 같은 작업을 수행합니다.
        1. 단기 스케줄러: 프로세서의 사용을 제어하고, 프로세스 스케줄링을 처리합니다. 프로세서 사용 시간은 작은 단위로 측정되며, 대개 밀집된 CPU 사용이 이루어집니다. 예를 들어, 리눅스 운영 체제의 단기 스케줄러는 CFS (Completely Fair Scheduler)입니다.
        2. 중기 스케줄러: 메모리에서 프로세스를 잠시 제거하고 나중에 다시 메모리에 적재하여 시스템 리소스의 효율성을 높이는데 사용됩니다. 이것은 일반적으로 프로세스의 I/O 요구사항이나 사용자 입력을 대기하면서 대기하는 프로세스에 사용됩니다.
        3. 장기 스케줄러: 프로세스 생성 요청을 대기열에 추가하고, 이 대기열에서 새로운 프로세스를 선택하여 실행 가능한 프로세스로 이동시키는 것입니다. 이 스케줄러는 운영 체제가 최적의 성능을 내도록 시스템 리소스를 관리하는 데 중요한 역할을 합니다.
        
        각 스케줄러는 다른 시간 단위에서 작동하며, 서로 다른 목적을 가지고 있습니다. 이들 스케줄러는 모두 현대 운영 체제에서 사용되며, 시스템 성능을 최적화하고 사용자가 보다 빠르고 효율적으로 작업을 수행할 수 있도록합니다.
        
2. 프로세스의 스케쥴링 상태에 대해 설명해 주세요.
    - 
        
        운영 체제에서 프로세스는 여러 상태를 가질 수 있습니다. 이러한 상태는 프로세스의 실행 상태, 프로세스의 I/O 상태, 프로세스가 대기 중인 상태 등입니다. 다음은 프로세스의 스케줄링 상태에 대한 설명입니다.
        
        1. 실행(Running) 상태: 프로세스가 현재 CPU에서 실행 중인 상태입니다.
        2. 준비(Pready) 상태: CPU를 할당받기 위해 대기 중인 프로세스 상태입니다. 이 상태의 프로세스는 CPU 자원을 대기하면서 메모리에 상주하며 언제든지 CPU를 할당받을 수 있습니다.
        3. 대기(Blocked) 상태: I/O나 다른 이벤트를 기다리는 상태입니다. 이 상태의 프로세스는 해당 이벤트가 발생하기 전까지 대기합니다.
        4. 생성(New) 상태: 프로세스가 생성되었지만 아직 메모리 할당을 받지 않은 상태입니다.
        5. 완료(Terminated) 상태: 프로세스가 작업을 완료하고 종료된 상태입니다.
        
        이러한 스케줄링 상태는 운영 체제가 CPU와 메모리를 효율적으로 사용하기 위해 중요합니다. 운영 체제는 스케줄링 알고리즘을 사용하여 프로세스를 이러한 상태 간에 전환하며, 이를 통해 CPU 자원을 최대한 활용하고 성능을 개선합니다.
        
3. preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요
    - 
        
        preemptive 스케줄링에서는 CPU가 실행 중인 프로세스를 강제로 중단시키고 다른 프로세스에게 CPU를 할당할 수 있습니다. 따라서 preemptive 스케줄링에서는 모든 프로세스가 언제든지 CPU 자원을 빼앗길 수 있으므로, 모든 프로세스는 언제든지 준비(Ready) 상태에 있어야 합니다.
        
        따라서 preemptive 스케줄링에서는 모든 상태가 존재할 수 있지만, 일부 상태는 짧은 순간 동안만 존재할 수 있습니다. 예를 들어, 실행(Running) 상태의 프로세스가 다른 이벤트를 기다리는 대기(Blocked) 상태로 바뀔 때, 이 프로세스는 강제로 중단될 수 있습니다. 이 경우 프로세스는 일시적으로 대기(Blocked) 상태에 있을 수 있지만, 빠르게 다시 준비(Ready) 상태로 전환됩니다. 따라서 preemptive 스케줄링에서도 모든 상태가 존재할 수 있지만, 일부 상태는 매우 짧은 순간 동안만 존재할 수 있습니다.
        
        non-preemptive 스케줄링에서는 CPU가 실행 중인 프로세스를 완료할 때까지 다른 프로세스에게 CPU를 할당하지 않습니다. 따라서 실행(Running) 상태의 프로세스가 중간에 강제로 중단되는 경우는 없습니다. 따라서 non-preemptive 스케줄링에서는 실행(Running) 상태에서 다른 상태로 바뀌는 경우를 제외하고는 모든 상태가 존재할 수 있습니다.
        
        다만, non-preemptive 스케줄링에서는 실행(Running) 상태의 프로세스가 I/O 요청 등 다른 이벤트를 기다리는 대기(Blocked) 상태가 되는 경우가 많습니다. 이 경우 실행(Running) 상태에서 대기(Blocked) 상태로 전환되는 것은 non-preemptive 스케줄링에서도 가능합니다.
        
4. Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?
    - 
        
        Memory가 부족할 경우, 프로세스는 다음과 같은 상태로 변화할 수 있습니다.
        
        1. 대기(Blocked) 상태: 필요한 메모리 공간을 할당받기 위해 대기 상태가 될 수 있습니다. 메모리 공간이 부족하면 운영체제는 일시적으로 프로세스를 중지하고 다른 프로세스를 실행시키고, 메모리 공간이 확보될 때까지 기다리게 됩니다.
        2. 스왑(스왑아웃) 상태: 메모리에 상주하고 있는 프로세스 중 일부는 디스크로 스왑(스왑아웃)될 수 있습니다. 이렇게 메모리에서 디스크로 이동하는 것을 스왑아웃(Swap-out) 또는 페이지아웃(Page-out)이라고 하며, 디스크에서 메모리로 다시 로드하는 것을 스왑인(Swap-in) 또는 페이지인(Page-in)이라고 합니다.
        3. 종료(Terminated) 상태: 메모리가 부족한 상황에서도 필요한 메모리를 할당받지 못하면, 프로세스는 종료(Terminated) 상태가 될 수 있습니다.
        
        이러한 상태 변화는 운영체제가 메모리 관리를 위해 사용하는 스와핑(Swapping), 페이지 교체(Page Replacement), 가상 메모리(Virtual Memory) 등의 기술을 사용하여 조절됩니다.
